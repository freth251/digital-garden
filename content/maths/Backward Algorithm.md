#maths 
The backward algorithm is a mirror of the [[Forward Algorithm]], where instead of computing the likelihood of being in a certain state given the observations that came before it, we compute the likelihood of being in a certain state knowing future observations.

$$
\begin{align*}
\text{Initialization:} \quad & \beta_T(X_i) = 1, & 1 \leq i \leq N \\
\text{Recursion:} \quad & \beta_{t-1}(i) = \sum_{j=1}^{N} \beta_t(X_j) P(X_j|X_i) P(Y^t|X_j), & 1 \leq t \leq T-1, 1 \leq i \leq N \\
\text{Termination:} \quad & P(O) = \sum_{j=1}^{N}\pi[j] P(Y^0|X_j)\beta_{1}(j), &
\end{align*}
$$

## Example

Let's say we got observer $O=\{ğŸ˜«,ğŸ˜ƒ\}$. To compute the likelihood of this observation with the backward algorithm, we will have: 

$$
\begin{align*}
\underline{Initialization:} \\
\\
t=1: \ & \beta_2(â˜€ï¸)= 1, \\ 
& \beta_2(â˜ï¸)= 1,\\
& \beta_2(â›ˆ)= 1 \\
\\
\underline{Recursion:} \\
\\
t=2 : \ & \beta_1(â˜€ï¸)=[\beta_2(â˜€ï¸)P(â˜€ï¸|â˜€ï¸)+\beta_2(â˜ï¸)P(â˜€ï¸|â˜ï¸) +\beta_1(â›ˆ)P(â˜€ï¸|â›ˆ)]P(ğŸ˜ƒ|â˜€ï¸) \\
& \beta_1(â˜ï¸)=[\beta_2(â˜€ï¸)P(â˜ï¸|â˜€ï¸)+\beta_2(â˜ï¸)P(â˜ï¸|â˜ï¸) +\beta_2(â›ˆ)P(â˜ï¸|â›ˆ)]P(ğŸ˜ƒ|â˜ï¸) \\
& \beta_1(â›ˆ)=[\beta_2(â˜€ï¸)P(â›ˆ|â˜€ï¸)+\beta_2(â˜ï¸)P(â›ˆ|â˜ï¸) +\beta_2(â›ˆ)P(â›ˆ|â›ˆ)]P(ğŸ˜ƒ|â›ˆ) \\
\ \\
\underline{Termination:} & \\
\\
P(O)= &\beta_1(â˜€ï¸)\pi[â˜€ï¸]P(ğŸ˜«|â˜€ï¸)\\ +  &\beta_1(â˜ï¸)\pi[â˜ï¸]P(ğŸ˜«|â˜ï¸) \\ + &\beta_1(â›ˆ)\pi[â›ˆ]P(ğŸ˜«|â›ˆ)

\end{align*}
$$
